\chapter{MICROSERVIÇOS: CONCEITOS E TECNOLOGIAS}
\label{chp:tecnologias}

Para o desenvolvimento deste projeto, são necessárias diversas tecnologias e
conceitos, os quais envolvem várias áreas da computação. Neste capítulo são
abordados os principais assuntos relacionados ao foco principal deste documento.

\section{ARQUITETURAS}

Segundo \citeonline{Tanenbaum2007}, houve diversas tentativas de criar
arquiteturas de softwares resistente a falhas e manteníveis. A criação de
novas tecnologias, como acesso a virtualização instantânea de baixo custo,
e algumas mudanças de paradigmas de estruturação dos projetos (maior foco
na escalabilidade do que na otimização de baixo nível) criaram a
necessidade destas arquiteturas se adaptarem e evoluirem suprir estes
novos requisitos.

\subsection{Monolítica}

O modelo clássico de desenvolvimento de qualquer projeto é composto por um
único processo responsável pela entrega de todas as funcionalidades de um
produto. Empresas como Google, Amazon e Netflix utilizaram por muito tempo
esta arquitetura, principalmente pelo baixo custo de infraestrutura inicial,
tendo em vista que o custo de manutenção envolve somente a manutenção deste
único binário e de seus dados.

Segundo \citeonline{Erl2008}, este modelo é válido e recomendado para novos
projetos, considerando que nem sempre as linhas de separação entre as regras
de negócio estão bem definidas. Este processo ocorre naturalmente durante o
ciclo de vida de um projeto, e muitas vezes a separação por bibliotecas e
módulos no código já é suficiente para o isolamento de domínios.

Segundo \citeonline{Nygard2007}, os problemas deste formato iniciam conforme
a base de código cresce e a demanda de novas funcionalidades aumentam. Uma
grande base de código que deve ser empacotada e levada a produção de uma
única vez cria uma grande inércia no desenvolvimento de novas
funcionalidades, pois alterações em uma funcionalidade tem sua liberação
atrasada por causa de alterações em outras partes do código não
relacionadas, mas que fazem parte do mesmo repositório de código.

Esta arquitetura atende muito bem alguns tipos de produtos, mas aplicações
expostas para internet que podem ter milhares de acessos simultâneos expõe o
principal ponto fraco deste formato: escalabilidade. Segundo
\citeonline{Namiot2014}, este problema ocorre quando uma funcionalidade do
monolíto tem um aumento de demanda maior que o limite físico de uma única
máquina, sendo necessário alocar outra instância da aplicação, mas para isto
é necessário alocar recursos para todas as funcionalidades, uma vez que o
software é composto de um único binário. Estes recursos alocados
desnecessariamente aumentam muito o custo de operação e manutenção do
sistema, o que reflete diretamente no negócio que depende deste.

\subsection{Service oriented architecture}

Para criar o isolamento das aplicações necessário para atender as novas
necessidades destes ambientes, foram criados um conjunto de conceitos
que englobam o que é chamado de \ac{SOA}. Estes conceitos definem algumas
regras e diretrizes para isolamento de domínios de aplicações e comunicação
entre as diversas partes do sistema.

Segundo \citeonline{Erl2008}, este formato de arquitetura segue alguns
princípios que determinam a classificação de um sistema como \ac{SOA},
os quais são:

\begin{alineas}
  \item contratos de comunicação padronizados;
  \item baixo nível de acoplamento;
  \item abstração da regra de negócio;
  \item reusabilidade de um serviço;
  \item autonomia de um serviço;
  \item inexistência de manutenção de estados;
  \item descoberta de serviços;
  \item componibilidade de serviços.
\end{alineas}

Contratos de comunicação padronizados se referem ao estabelecimento de
formatos de dados e métodos de interação entre os serviços. Segundo
\citeonline{Fowler2002}, um dos padrões de APIs SOA mais popular é o
\ac{SOAP}, que define um formato padronizado de comunicação de
aplicações utilizando dados no formato \ac{XML}. Este padrão é flexível,
e permite a criação de implementações mais específicas, como o \ac{WSDL},
que expõe um protocolo \ac{RPC} utilizando este padrão como meio.

Baixo nível de acoplamento, de acordo com \citeonline{Josuttis2007}, é um
conceito que aborda o isolamento de domínios de aplicação e as
interdependências entre serviços, os quais não devem depender da forma
como são implementados outros serviços. Isto conflita em alguns pontos
com contratos de comunicação utilizando \ac{RPC}, pois o mesmo simula
o funcionamento de um sistema monolítico. Para tal, é utilizado
\emph{middlewares} chamados \ac{ESB}, os quais permitem comunicação
assíncrona entre os serviços que compõe o sistema.

Abstração da regra de negócio é a forma como os serviços devem expor
seus contratos de comunicação, onde um serviço deve expor funcionalidades
e não a sua implementação, permitindo que um serviço seja alterado internamente
sem que isto afete outros serviços dependentes do serviço em questão.

Reusabilidade de um serviço, conforme explica \citeonline{Erl2008} deve-se
ao fato que existe poucas vantagens em isolar uma regra de negócio utilizada
exclusivamente por um único serviço. Uma regra de negócio deve se tornar um
serviço isolado somente se ela for utilizada por mais sistemas, caso
contrário este serviço estaria somente adicionando complexidade ao sistema.

Autonomia de um serviço refere-se ao fato que falhas em partes de aplicação
são um risco que não pode ser mitigado de forma simples. Para isto, serviços
devem estar preparados para situações de falha em outros serviços, onde
o serviço precisa entregar sua funcionalidade independente de outros serviços
estarem operacionais. No caso de sistemas monolíticos uma falha
em uma parte da aplicação poderia matar o processo e indisponibilizar
a aplicação como um todo, no caso de sistemas implementados com \ac{SOA}, os
serviços devem continuar a disponibilizar, na medida do possível, suas
funcionalidades mesmo que um serviço o qual este depende apresente algum tipo
de problema.

Inexistência de manutenção de estados, segund \citeonline{Richardson2007}, é
um conceito que existe porque manter estado de um cliente de um serviço
consome recursos e tempo de computação que podem ser evitados caso não seja
mantido estados. Para tal, cada requisição na comunicação deve carregar
todas as informações necessárias para realizaçao da operação. Este conceito
de comunicação é aplicado em diversos protocolos de comunicação assincronos,
como por exemplo o \ac{HTTP}, os quais, por limitações físicas, não podem
manter estados a fim aumentar sua resistência a falhas em casos de erros de
comunicação.

Descoberta de serviços, conforme explica \citeonline{Newman2015}, é a
possibilidade de um sistema composto por diversos serviços deve conseguir
descobrir onde os serviços estão rodando e como acessa-los. Isto pode ser
feito por meio de um registro de serviços, que armazena uma lista de serviços
atualmente em execução. Esta funcionalidade também é utilizada para alta
disponibilidade e distribuição de carga, uma vez que este registro pode
apontar para mais de uma instância do mesmo serviço. Um exemplo prático das
vantagens deste princípio é uma manobra de manutenção em um servidor, onde
pode ser removido o apontamento de uma instância do registro de serviços sem
que haja paradas no sistema.

Componibilidade de serviços engloba alguns conceitos de \ac{OOP} na criação
de serviços, onde um serviço que expõe uma regra de negócio pode ser composto
por funcionalidades expostas por outros serviços.

\begin{figure}[H]
	\centering
	\caption{Composição da regra de negócio por meio de serviços}
	\includegraphics[width=1.0\textwidth]{figuras/soa-bussiness-rules.png}

	\label{fig:soa-bussiness-rules}
	\footnotesize Fonte: \citeonline{Erl2008}
\end{figure}

Segundo \citeonline{Erl2008}, por meio deste conceito as camadas de serviço
podem depender de outras camadas de serviços. Isto permite o reuso de lógica
de aplicações completamente diferentes para compor uma nova aplicação, o que
é possível somente se outros princípios como o baixo acoplamento e isolamento
da regra de negócio forem aplicados corretamente. Uma grande vantagem da
aplicação deste conceito é que diferentes aplicações podem compartilhar uma
mesma infraestrutura de serviços.

\subsection{Microserviços}

Microserviços, segundo \citeonline{Boner2016}, são um formato de
desenvolvimento de sistemas que trata o problema de isolamento dos domínios
da aplicação por meio da distribuição da lógica entre pequenos processos
independentes que trabalham em conjunto para a entrega da funcionalidade
final esperada.

Esta arquitetura surgiu de práticas aplicadas por empresas de escala global que
operam na internet, muito antes de haver uma classificação para tal. Estas
práticas se enquadram como um subconjunto dos conceitos de \ac{SOA}, mas se
diferenciam em alguns pontos das tecnologias tradicionais por impor práticas
que focam na entrega rápida e na produtividade dos times envolvidos com
o produto.

Segundo \citeonline{Newman2015}, arquiteturas de microserviços não se limitam
somente a arquitetura de software, se estendendo sobre a forma como são
realizadas as entregas de novas versões, no gerenciados os ambientes
de operação, no versionamento do software como um todo e no armazenamento de
dados da aplicação, como apresentado na Figura \ref{fig:venn-microservices},
que apresenta a intersecção de conceitos que trabalham em conjunto para criar
os microserviços.

\begin{figure}[H]
	\centering
	\caption{Diagrama de conceitos de Microserviços}
	\includegraphics[width=1.0\textwidth]{figuras/venn-microservices.png}

	\label{fig:venn-microservices}
	\footnotesize Fonte: \citeonline{Goldsmith2015}
\end{figure}

O baixo acoplamento neste formato de arquitetura é levado um passo a frente.
Segundo \citeonline{Newman2015}, realizando a separação de domínios da
aplicação por meio de isolamento dos executáveis e do código que compõe os
serviços, esta arquitetura permite que serviços sejam escritos em linguagens
diferentes, o que permite de utilizar tecnologias diferentes caso exista
a necessidade.

Esta separação da aplicação a nível de regras de negócio é chamada de \ac{DDD},
e não é exclusiva de microserviços. Segundo \citeonline{Millet2015}, \ac{DDD}
é um processo que alinha o código da aplicação com o domínio do problema
a ser resolvido, facilitando o entendimento em futuras manutenções e
alterações nesta aplicação. O desenvolvimento de serviços focados em uma
única regra de negócio reduz a carga de conhecimento que o desenvolvedor
precisa estar ciente antes de realizar alterações em uma base de código.

Conforme explica \citeonline{Stine2015}, o versionamento e a entrega de
atualizações neste modelo de arquitetura também se diferencia, por exigir
que o versionamento dos serviços sejam independentes entre si. Isto permite
que entregas de novas funcionalidades sejam realizadas independentemente de
outros serviços, aumentado a produtividade dos times envolvidos, uma vez que
cada um pode realizar entregas sem depender de prazos e atrasos de outras
equipes.

Segundo \citeonline{Stine2015}, a aplicação desta arquitetura só funciona
quando há uma alteração nos processos e na cultura de toda a área técnica
de uma empresa, pois envolvem a aplicação de técnicas de \ac{CI} e \ac{CD},
além de times serem compostos por integrantes multidisciplinares. Muitos dos
conceitos aplicados a microserviços tiveram algumas raízes nas metodologias
ágeis, como Scrum, XP e Lean, o que torna a aplicação desta arquitetura nos
produtos de uma empresa uma alteração na forma como a própria empresa trabalha.

Os benefícios na produtividade e na qualidade do software entregue pode
ser claramente vistos na tese de mestrado de \citeonline{Lopes2015}, um estudo
de caso de migração da arquitetura dos produtos de uma empresa para
microserviços, na qual houveram aumentos significativos na velocidade de
entrega de software funcional e na diminiuição dos bugs encontrados em
produção.

\section{TECNOLOGIAS APLICADAS}

Para a aplicação da arquitetura de microserviços, é necessário uma gama de
tecnologias e conceitos. Neste capítulo serão abordados os conceitos criação
de APIs externas expostas pela aplicação, as tecnologias de comunicação entre
microserviços, os padrões de armazenamento de dados e uma das plataformas de
execução destas aplicações.

\subsection{Representational State Transfer}

\ac{REST} é um padrão de criação de \acp{API} que se popularizou com a
adoção em massa por grandes empresas da internet. Ele define algumas práticas
para estruturação das \acp{URL} por meio da utilização do que ele chama de
recursos, que são elementos da aplicação responsáveis por armazenamento ou
tomada de ações, que podem ser isolados a nível da regra de negócio que os
engloba. Segundo \citeonline{Saudate2013}, este padrão pode ser considerado
como uma aplicação de \acp{API} orientadas a recursos. Alguns exemplos
de recursos são usuários, \emph{tickets} de um sistema de controle de bugs e
notas fiscais de um software de \ac{ERP}.

Cada recurso dentro da \ac{API} pode ter um conjunto de ações que podem ser
aplicadas sobre ele, que são apresentadas por meio de métodos \ac{HTTP} ou
por sub-\acp{URL} para ações mais específicas. O conjunto de ações mais
comuns é o \ac{CRUD}, as quais são operações básicas de manipulação de dados,
que são traduzidos para os métodos \emph{POST}, \emph{GET}, \emph{PUT} e
\emph{DELETE} para utilização nas \acp{API}.

Um excelente exemplo de aplicação, como apresentado por
\citeonline{Richardson2007}, é a \ac{API} da aplicação S3 da Amazon, que é
um serviço de armazenamento de arquivos e dados. Nesta aplicação, são
utilizados dois recursos principais, os \emph{Buckets} e os \emph{Objects},
onde \emph{Objects} são as unidades de armazenamento de dados e \emph{Buckets}
são containers que contém multiplas unidades de armazenamento, sendo cada
um destes recursos manipulados por \acp{API} dedicadas para criação e
manipulação dos mesmos.

Conforme \citeonline{Ignacio2009}, o padrão \ac{REST} funciona muito bem
em conjunto com microserviços, por aplicar algumas práticas de separação
de funcionalidades por meio de isolamento de recursos relacionados. No
estudo de caso deste artigo, é apresentado a criação de uma \ac{API} no
estilo \ac{REST} de pesquisa, na qual o recurso apresentado é o objeto
alvo da pesquisa, o qual é repassado para microserviços que funcionam
como intermediários para busca em motores de busca disponíveis no mercado.

\subsection{Banco de dados}

Segundo \citeonline{Boner2016}, uma prática aplicada que visa diminuir o
acoplamento das rotinas do sistema é o isolamento da base de dados de cada
domínio de aplicação. A recomendação é cada serviço ter sua própria base de
dados e seja o único responsável por ela, impedindo assim que outros serviços
realizem alterações indevidas nos dados de outros domínios. Na Figura
\ref{fig:db-monolith-microservices} é apresentado um diagrama comparativo do
armazenamento de dados de uma arquitetura monolítica e de microserviços:

\begin{figure}[H]
	\centering
	\caption{Armazenamento de dados em monolítos e microserviços}
	\includegraphics[width=1.0\textwidth]{figuras/decentralised-data.png}

	\label{fig:db-monolith-microservices}
	\footnotesize Fonte: \citeonline{Fowler2016}
\end{figure}

Em outras arquiteturas, são aplicadas grandes estruturas relacionais de banco
de dados, onde o relacionamento entre os diversos dados da aplicação são
aplicados a estrutura de armazenamento de dados. Isto gera alguns problemas,
o mais grave sendo a incerteza de quais partes da aplicação utilizam uma
seção dos dados, o que pode gerar inconsistencias na gravação e leitura dos
mesmos.

Conforme explica \citeonline{Newman2015}, este problema não deve existir
dentro da arquitetura de microserviços, pois o acesso aos dados de outros
domínios da aplicação devem ser feitos por meio do microserviço responsável.
Para tal, são utilizados sistemas de comunicação entre os serviços, como por
exemplo as \acp{MQ}, que funcionam como \acp{API} internas da aplicação.

\subsection{Message queues}

\emph{Message Queue} é um formato de envio e distribuição de mensagens
entre processos, no qual é utilizado padrões independentes de linguagens
de programação específicas, que permitem a comunicação entre sistemas que
utilizam diferentes tecnologias. Esta comunicação é feita por meio de
mensagens, as quais são geradas por um produtor e recebidas por um receptor
ou assinante. Estes softwares fornecem algumas funcionalidades similares aos
\acp{ESB} do \ac{SOA}.

Segundo \citeonline{Videla2012}, exitem 3 principais padrões de comunicação
utilizados em \acp{MQ}, send o primeiro chamado \emph{request-reply}, onde
mensagens são enviadas de um processo para o outro e para cada mensagem o
produtor espera receber uma mensagem de resposta do receptor. Pode ser feita
uma analogia a uma chamada de função de uma linguagem de programação, onde os
parâmetros são a mensagem enviada pelo produtor e o retorno da função é a
mensagem de resposta.

O segundo padrão é o \emph{work queue}, onde as mensagens são enviadas pelo
produtor, mas este não espera uma resposta do receptor. Este formato é
utilizado para tratamento de dados em que o momento de execução do
processamento destes não é deterministico, ou seja, o produtor não utiliza
os resultados da mensagem que ele enviou, ficando a cargo do do receptor
encaminhar e/ou notificar interessados nos dados em questão.

O último padrão de comunicação de \acp{MQ} é o \emph{publisher-subscriber}.
Conforme explica \citeonline{Newman2015}, este padrão funciona por meio de
um produtor (o \emph{publisher}) que envia uma mensagem para um tópico, o
qual assinantes ouvem para receber qualquer mensagem que seja enviado para
este, como apresentado na Figura \ref{fig:mq-pubsub}. Este formato de
comunicação se assemelha ao conceito de \emph{broadcast} de redes de
computadores, onde uma mensagem é enviada sem um destinatário específico,
e todos que estiverem ouvindo podem receber esta mensagem.

\begin{figure}[H]
	\centering
	\caption{Padrão publisher-subscriber de comunicação}
	\includegraphics[width=0.7\textwidth]{figuras/mq-pubsub.png}

	\label{fig:mq-pubsub}
	\footnotesize Fonte: \citeonline{Microsoft2016}
\end{figure}

Para enteder o último padrão, é necessário antes entender os tipos de \acp{MQ}
existentes, as quais podem ser \emph{brokered} ou \emph{brokerless}. Segundo
\citeonline{Hintjens2013}, a diferença entre estes dois reside na existência
ou não de um \emph{broker}, respectivamente. Um \emph{broker} é em essência um
distribuidor de mensagens centralizado, um meio no qual os serviços podem
utilizar para enviar mensagens.

Na Figura \ref{fig:mq-coupling} é exibido uma representação visual destes dois
modelos, sendo o primeiro a comunicação \emph{brokerless}, onde cada serviço
precisa saber da existência dos outros para enviar mensagens, e o segundo é
o modelo \emph{brokered}, onde o \emph{broker} é responsável por distribuir
as mensagens entre os diferentes serviços.

\begin{figure}[H]
	\centering
	\caption{Comunicação \emph{brokerless} e \emph{brokered}}
	\includegraphics[width=1.0\textwidth]{figuras/mq-coupling.png}

	\label{fig:mq-coupling}
	\footnotesize Fonte: \citeonline{Microsoft2016}
\end{figure}

Segundo \citeonline{Videla2012}, existem algumas vantagens na utilização
de \acp{MQ} centralizadas, sendo uma delas o baixo acoplamento da comunicaçao
entre serviços, os quais não precisam diretamente se comunicar com outros
serviços. Outra vantagem é o fato deste serviço de \ac{MQ} funcionar como
um \emph{cache} de mensagens, se um serviço estiver estiver fora do ar as
mensagens destinadas a este podem ser armazenadas temporariamente. Uma
desvantagem é a inclusão de um ponto único de falha, uma vez que o serviço
de \ac{MQ} se torna crítico para operação dos serviços.

\subsection{Containers Linux}

Containers são uma nova tecnologia de criação de ambientes isolados que tem
como objetivo substituir máquinas virtuais em algumas situações. Máquinas
virtuais e containers compartilham o conceito de isolamento de ambientes, mas
este é o limite das semelhanças entres os dois, pois o primeiro foca na
emulação de uma máquina física completa, e o segundo foca somente no
isolamento de arquivos e bibliotecas utilizadas por uma aplicação.

O conceito de criação de ambientes isolados já existia a bastante tempo, mas
por falta de ferramentas para facilitar sua utilização e algumas limitações
de segurança não permitiram a proliferação destas ferramentas antes da criação
do Docker.

O Docker é um conjunto de ferramenta de criação e distribuição de containers,
que utiliza algumas tecnologias disponíveis no kernel Linux para criação de
containers para rodar aplicações com segurança dentro de um \emph{sandbox},
na qual a aplicação só consegue interagir com o seu próprio ambiente. A criação
de containers é feita por meio de imagens, as quais são distribuidas em
repositórios públicos de imagens, nos quais estão disponíveis imagens prontas
para diversos serviços e tecnologias. Também existe a possibilidade de ser
criado um repositório privado, caso alguma política de controle de licenças
não permita a criação de repositórios públicos.

A idéia de ter imagens públicas disponíveis para qualquer pessoa é a de
utilizar containers como blocos de montar para aplicações. Por exemplo,
em uma aplicação web, pode ser criado um container para rodar o servidor de
aplicação e utilizar imagens disponíveis para o serviço de banco de dados e
o servidor de arquivos estáticos. A comunicação entre estes containers é feita
por meio de uma rede virtual entre os containers que permite a comunicação
entre os mesmos como se estivessem rodando em máquinas separadas.

O isolamento de bibliotecas e dependências por meio de containers permite
executar aplicações distintas dentro da mesma máquina sem que exista
conflitos de versões dos requisitos para rodar estas aplicações. Isto é feito
por meio da utilização de instalações de sistemas operacionais mínimas dentro
de cada container, sem kernel e arquivos desnecessários para operação das
aplicações.

Isto normalmente usaria muito espaço para manter um sistema completo para
cada serviço da aplicação, mas o Docker cria o que ele chamda de camadas
de arquinos, na qual cada imagem é composto por camadas que podem ser
reutilizadas por imagens derivadas. Por exemplo, existe imagens das
versões da distribuição Linux Debian, que são utilizados pelos criadores da
imagem do banco de dados PostgreSQL e da imagem do servidor web Apache.
Ao utilizar estas duas últimas imagens na mesma máquina, o espaço em disco
da camada do Debian será utilizada uma única vez, para cada container será
adicionado somente a diferença de espaço em disco necessário para os arquivos
específicos da imagem do container.

Ao rodar o container, as camadas da imagem são montadas no disco em modo
somente leitura, sendo que alterações realizadas dentro do container são
armazenadas separadamente para cada container. Este processo é invisível para
a aplicação, a qual enxerga um sistema de arquivos normal.

Por todos os serviços compartilharem o mesmo kernel, o isolamento precisa
ser também a nível de processos. Conforme explica \citeonline{Newman2015},
o kernel Linux implementa uma tecnologia chamada \emph{cgroups}, que é uma
forma de criar subárvores de processos isoladas dentro do kernel, as quais
tem sua própria numeração dos processos. Desta forma cada container não
conseguem interferir com processos do host e de outros containers.
